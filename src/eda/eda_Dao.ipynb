{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "df = pd.read_csv('.././data/raw/all_teams_data.csv')\n",
    "pd.options.display.max_columns = None\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lọc ra các trận ngoài La Liga\n",
    "--> Có thể tạo thêm feature: Có đá giữa tuần không?\n",
    "--> Độ quan trọng (đánh trọng số) cho trận giữa tuần --> Vì có ảnh hưởng đến trận cuối tuần đá League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "df['Comp'].value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý Null p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sơ sài --> Phải xử lý kĩ hơn: tìm cách dùng src\\preprocessing\\handle_missing_values.py, etc ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df.replace('', np.nan, inplace=True)\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = df.isnull().mean() * 100\n",
    "missing_percentage[missing_percentage > 10]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La Liga data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "df = df[df['Comp'] == 'La Liga']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "len(df.columns.to_list())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "# columns_to_drop = [col for col in df.columns if col.startswith('Expected') or col.startswith('x')]\n",
    "\n",
    "# df.drop(columns=columns_to_drop, inplace=True)\n",
    "# df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "%cd ../"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "from preprocessing.preprocess import *\n",
    "df2 = preprocess_data(df)\n",
    "df2.sort_values(by='Time', inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý các cột dạng object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Có thể làm kĩ hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "object_columns = df2.select_dtypes(include=['object']).columns\n",
    "print(object_columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "# df2.drop(columns = ['Captain', 'Formation', 'Opp Formation'], inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý Null p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nghiên cứu kĩ hơn các cột còn lại & Ít quá thì fill thẳng missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df2.replace('', np.nan, inplace=True)\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = df2.isnull().mean() * 100\n",
    "sorted(missing_percentage[missing_percentage > 0].items(), key=lambda x: x[1], reverse=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G/SoT missing because SoT = 0\n",
    "\n",
    "Save% missing because SoT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many seasons are there ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "num_seasons = df2['Season'].nunique()\n",
    "print(f'There are {num_seasons} seasons in the data.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "df2['Season'].unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many teams are there ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "num_teams = df2['Team'].nunique()\n",
    "print(f'There are {num_teams} teams in the data.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "df2['Opponent'] = df2['Opponent'].apply(unidecode)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "df2.loc[df2['Opponent'] == 'La Coruna', 'Opponent'] = 'Deportivo La Coruna'\n",
    "df2.loc[df2['Opponent'] == 'Betis', 'Opponent'] = 'Real Betis'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "df2.to_csv('clean_data.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many decisive games ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "decisive_games = df2[df2['Result'] != 'D'].shape[0]\n",
    "print(f'There are {decisive_games / 2} decisive games in the data.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall results of each team through out 8 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the number of wins, draws, and losses for each team\n",
    "results = df2.groupby('Team')['Result'].value_counts().unstack().fillna(0)\n",
    "results.columns = ['Draws', 'Losses', 'Wins']\n",
    "# Calculate total matches and win, draw, loss percentages\n",
    "results['Total Matches'] = results.sum(axis=1)\n",
    "results['Win %'] = (results['Wins'] / results['Total Matches']) * 100\n",
    "results['Draw %'] = (results['Draws'] / results['Total Matches']) * 100\n",
    "results['Loss %'] = (results['Losses'] / results['Total Matches']) * 100\n",
    "\n",
    "# Sort the columns order\n",
    "results = results[['Total Matches', 'Wins', 'Win %', 'Draws', 'Draw %', 'Losses', 'Loss %']]\n",
    "\n",
    "# Add 'Team' column\n",
    "results = results.reset_index()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which teams have the highest win %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "results.sort_values(by='Win %', ascending=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which teams score the most goals ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the number of goals for, goals against, goals diff of each team\n",
    "team_goals = df2.groupby('Team').agg({\n",
    "    'GF': 'sum',\n",
    "    'GA': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate Goal Difference (GD)\n",
    "team_goals['GD'] = team_goals['GF'] - team_goals['GA']\n",
    "\n",
    "# Sort the teams by Goal Difference\n",
    "team_goals = team_goals.sort_values(by='GD', ascending=False)\n",
    "\n",
    "team_goals"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final table of each seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for season in sorted(df2['Season'].unique()):\n",
    "    table = df2[df2['Season'] == season].groupby('Team')\n",
    "    result_sum = table['Points'].sum().sort_values(ascending=False)\n",
    "    print(f'Season {season} - Total Results: {result_sum}')\n",
    "    num_matches = table['Points'].count()\n",
    "    if num_matches.iloc[0] != 38:\n",
    "        print(f\"Warning: The number of matches for season {season} is {num_matches.iloc[0]}, which is different from 38.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first 5 best teams\n",
    "plt.figure(figsize=(14, 8))\n",
    "for team in results.sort_values(by='Win %', ascending=False)['Team'].head(5):\n",
    "    team_data = df2[df2['Team'] == team]\n",
    "    win_percentage = team_data.groupby('Season')['Result'].apply(lambda x: (x == 'W').mean() * 100)\n",
    "    plt.plot(win_percentage.index, win_percentage.values, label=team)\n",
    "\n",
    "plt.xlabel('Seasons')\n",
    "plt.ylabel('Win %')\n",
    "plt.title('Win Percentage of Top 5 Teams Over Seasons')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe univariate variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chia cột ra để eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "prematch_cols = ['Time',\n",
    " 'Comp',\n",
    " 'Round',\n",
    " 'Day',\n",
    " 'Venue',\n",
    " 'Opponent',\n",
    " 'Captain',\n",
    " 'Formation',\n",
    " 'Opp Formation',\n",
    " 'Referee',\n",
    " 'Season',\n",
    " 'Team']\n",
    "shooting_cols = ['Standard__Gls',\n",
    " 'Standard__Sh',\n",
    " 'Standard__SoT',\n",
    " 'Standard__SoT%',\n",
    " 'Standard__G/Sh',\n",
    " 'Standard__G/SoT',\n",
    " 'Standard__Dist',\n",
    " 'Standard__FK',\n",
    " 'Standard__PK',\n",
    " 'Standard__PKatt']\n",
    "goal_keeping_cols = ['Performance__SoTA',\n",
    " 'Performance__GA',\n",
    " 'Performance__Saves',\n",
    " 'Performance__Save%',\n",
    " 'Performance__CS',\n",
    " 'Performance__PSxG',\n",
    " 'Performance__PSxG+/-',\n",
    " 'Penalty Kicks__PKatt',\n",
    " 'Penalty Kicks__PKA',\n",
    " 'Penalty Kicks__PKsv',\n",
    " 'Penalty Kicks__PKm',\n",
    " 'Launched__Cmp',\n",
    " 'Launched__Att',\n",
    " 'Launched__Cmp%',\n",
    " 'Passes__Att (GK)',\n",
    " 'Passes__Thr',\n",
    " 'Passes__Launch%',\n",
    " 'Passes__AvgLen',\n",
    " 'Goal Kicks__Att',\n",
    " 'Goal Kicks__Launch%',\n",
    " 'Goal Kicks__AvgLen',\n",
    " 'Crosses__Opp',\n",
    " 'Crosses__Stp',\n",
    " 'Crosses__Stp%',\n",
    " 'Sweeper__#OPA']\n",
    "passing_cols = ['Total__Cmp',\n",
    " 'Total__Att',\n",
    " 'Total__Cmp%',\n",
    " 'Total__TotDist',\n",
    " 'Total__PrgDist',\n",
    " 'Short__Cmp',\n",
    " 'Short__Att',\n",
    " 'Short__Cmp%',\n",
    " 'Medium__Cmp',\n",
    " 'Medium__Att',\n",
    " 'Medium__Cmp%',\n",
    " 'Long__Cmp',\n",
    " 'Long__Att',\n",
    " 'Long__Cmp%',\n",
    " 'Ast',\n",
    " 'KP',\n",
    " '1/3',\n",
    " 'PPA',\n",
    " 'CrsPA',\n",
    " 'PrgP']\n",
    "pass_type_cols = ['Att',\n",
    " 'Pass Types__Live',\n",
    " 'Pass Types__Dead',\n",
    " 'Pass Types__FK',\n",
    " 'Pass Types__TB',\n",
    " 'Pass Types__Sw',\n",
    " 'Pass Types__Crs',\n",
    " 'Pass Types__TI',\n",
    " 'Pass Types__CK',\n",
    " 'Corner Kicks__In',\n",
    " 'Corner Kicks__Out',\n",
    " 'Corner Kicks__Str',\n",
    " 'Outcomes__Cmp',\n",
    " 'Outcomes__Off',\n",
    " 'Outcomes__Blocks']\n",
    "goal_shot_creation_cols = ['SCA Types__SCA',\n",
    " 'SCA Types__PassLive',\n",
    " 'SCA Types__PassDead',\n",
    " 'SCA Types__TO',\n",
    " 'SCA Types__Sh',\n",
    " 'SCA Types__Fld',\n",
    " 'SCA Types__Def',\n",
    " 'GCA Types__GCA',\n",
    " 'GCA Types__PassLive',\n",
    " 'GCA Types__PassDead',\n",
    " 'GCA Types__TO',\n",
    " 'GCA Types__Sh',\n",
    " 'GCA Types__Fld',\n",
    " 'GCA Types__Def']\n",
    "defensive_actions_cols = ['Tackles__Tkl',\n",
    " 'Tackles__TklW',\n",
    " 'Tackles__Def 3rd',\n",
    " 'Tackles__Mid 3rd',\n",
    " 'Tackles__Att 3rd',\n",
    " 'Challenges__Tkl',\n",
    " 'Challenges__Att',\n",
    " 'Challenges__Tkl%',\n",
    " 'Challenges__Lost',\n",
    " 'Blocks__Blocks',\n",
    " 'Blocks__Sh',\n",
    " 'Blocks__Pass',\n",
    " 'Int',\n",
    " 'Tkl+Int',\n",
    " 'Clr',\n",
    " 'Err']\n",
    "possession_cols = ['Poss',\n",
    " 'Touches__Touches',\n",
    " 'Touches__Def Pen',\n",
    " 'Touches__Def 3rd',\n",
    " 'Touches__Mid 3rd',\n",
    " 'Touches__Att 3rd',\n",
    " 'Touches__Att Pen',\n",
    " 'Touches__Live',\n",
    " 'Take-Ons__Att',\n",
    " 'Take-Ons__Succ',\n",
    " 'Take-Ons__Succ%',\n",
    " 'Take-Ons__Tkld',\n",
    " 'Take-Ons__Tkld%',\n",
    " 'Carries__Carries',\n",
    " 'Carries__TotDist',\n",
    " 'Carries__PrgDist',\n",
    " 'Carries__PrgC',\n",
    " 'Carries__1/3',\n",
    " 'Carries__CPA',\n",
    " 'Carries__Mis',\n",
    " 'Carries__Dis',\n",
    " 'Receiving__Rec',\n",
    " 'Receiving__PrgR']\n",
    "miscellaneous_cols = ['Performance__CrdY',\n",
    " 'Performance__CrdR',\n",
    " 'Performance__2CrdY',\n",
    " 'Performance__Fls',\n",
    " 'Performance__Fld',\n",
    " 'Performance__Off',\n",
    " 'Performance__Crs',\n",
    " 'Performance__Int',\n",
    " 'Performance__TklW',\n",
    " 'Performance__PKwon',\n",
    " 'Performance__PKcon',\n",
    " 'Performance__OG',\n",
    " 'Performance__Recov',\n",
    " 'Aerial Duels__Won',\n",
    " 'Aerial Duels__Lost',\n",
    " 'Aerial Duels__Won%']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "df2[prematch_cols].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "df2.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Cần làm hết các biến còn lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(data=df2, x='Venue', hue='Result')\n",
    "plt.title('Result Distribution by Venue')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add number of match played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "# Calculate win percentage and number of matches for each team under each referee\n",
    "referee_performance = df2.groupby(['Referee', 'Team'])['Result'].agg(\n",
    "    WinPercentage=lambda x: (x == 'W').mean() * 100,\n",
    "    MatchCount='count'\n",
    ").reset_index()\n",
    "\n",
    "# Find the referee with the highest win percentage for each team\n",
    "best_referee_for_team = referee_performance.loc[referee_performance.groupby('Team')['WinPercentage'].idxmax()]\n",
    "\n",
    "# Rename columns for clarity\n",
    "best_referee_for_team.columns = ['Referee', 'Team', 'Win %', 'Match Count']\n",
    "\n",
    "best_referee_for_team = best_referee_for_team[best_referee_for_team['Match Count'] > 2]\n",
    "\n",
    "# Sort by win percentage in descending order\n",
    "best_referee_for_team = best_referee_for_team.sort_values(by='Win %', ascending=False)\n",
    "\n",
    "print(best_referee_for_team)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "# Calculate win percentage for each formation\n",
    "formation_win_percentage = df2.groupby('Formation')['Result'].apply(lambda x: (x == 'W').mean() * 100).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "formation_win_percentage.columns = ['Formation', 'Win %']\n",
    "\n",
    "# Sort the formations by win percentage\n",
    "formation_win_percentage = formation_win_percentage.sort_values(by='Win %', ascending=False)\n",
    "\n",
    "formation_win_percentage"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "# Calculate win percentage and match count for each formation grouped by team\n",
    "formation_performance = df2.groupby(['Team', 'Formation'])['Result'].agg(\n",
    "    WinPercentage=lambda x: (x == 'W').mean() * 100,\n",
    "    MatchCount='count'\n",
    ").reset_index()\n",
    "\n",
    "# Find the formation with the highest win percentage for each team\n",
    "best_formation_for_team = formation_performance.loc[formation_performance.groupby('Team')['WinPercentage'].idxmax()]\n",
    "\n",
    "# Rename columns for clarity\n",
    "best_formation_for_team.columns = ['Team', 'Formation', 'Win %', 'Match Count']\n",
    "\n",
    "best_formation_for_team = best_formation_for_team[best_formation_for_team[\"Match Count\"] > 3]\n",
    "\n",
    "# Sort the results by win percentage in descending order\n",
    "best_formation_for_team = best_formation_for_team.sort_values(by='Win %', ascending=False)\n",
    "\n",
    "print(best_formation_for_team)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "for cols in shooting_cols:\n",
    "    sns.histplot(data=df2, x=cols, hue='Result', multiple='stack')\n",
    "    plt.title(cols)\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "# Map the 'Result' column to numerical values\n",
    "# result_mapping = {'W': 2, 'D': 1, 'L': 0}\n",
    "# df2['Result_num'] = df2['Result'].map(result_mapping)\n",
    "df2['GD'] = df2['GF'] - df2['GA']\n",
    "# Select only numeric columns\n",
    "numeric_df2 = df2.drop(columns=prematch_cols).select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df2.corr()\n",
    "\n",
    "result_correlation = correlation_matrix['GD'].round(3).sort_values(ascending=False)\n",
    "pd.options.display.max_rows = None\n",
    "result_correlation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of shooting stats with goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "source": [
    "correlation_matrix['GF'][shooting_cols]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of goal keeping stats with goals against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "correlation_matrix['GA'][goal_keeping_cols]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# df2.to_csv('D:\\dev\\project\\Football-Match-Prediction\\data\\processed/la_liga_data.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('D:\\dev\\project\\Football-Match-Prediction\\data\\processed/la_liga_data.csv')\n",
    "df2.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with correlation with GD lower than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "threshold = 0.2  # Set your threshold value here\n",
    "\n",
    "# Get the correlation values for the 'GD' column\n",
    "gd_correlation = correlation_matrix['GD']\n",
    "\n",
    "# Find columns with correlation lower than the threshold\n",
    "low_correlation_cols = gd_correlation[gd_correlation.abs() < threshold].index\n",
    "\n",
    "# Drop these columns from the dataframe\n",
    "df2.drop(columns=low_correlation_cols, inplace=True)\n",
    "\n",
    "print(f\"Dropped columns with correlation lower than {threshold}: {low_correlation_cols.tolist()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df2 = df2.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = numeric_df2.corr().abs()\n",
    "\n",
    "# Select the upper triangle of the correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with high correlation (exceeding 0.9)\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "\n",
    "# Drop the redundant features\n",
    "df2.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "print(f\"Removed redundant features: {to_drop}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "source": [
    "df2.columns.to_list()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = df2.isnull().mean() * 100\n",
    "sorted(missing_percentage[missing_percentage > 0].items(), key=lambda x: x[1], reverse=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "object_columns = df2.select_dtypes(include=['object']).columns\n",
    "print(object_columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "df2.drop(columns=['Referee', 'Captain', 'Comp', 'Formation', 'Opp Formation'], inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "source": [
    "for col in df2.select_dtypes(include=[np.number]).columns:\n",
    "    df2[col] = df2[col].fillna(df2.groupby('Team')[col].transform('mean'))\n",
    "    # df2[cols] = df2[cols].fillna(df2.groupby('Team')[cols].mean()) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = df2.isnull().mean() * 100\n",
    "sorted(missing_percentage[missing_percentage > 0].items(), key=lambda x: x[1], reverse=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "feature_cols = [col for col in df2.columns if col not in prematch_cols]\n",
    "feature_cols.remove('Result')\n",
    "categorical_cols = [col for col in feature_cols if col not in df2.select_dtypes(include=[np.number]).columns]\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "to_drop = ['Referee', 'Captain', 'Day', 'Comp', 'Season', 'Formation', 'Opp Formation']\n",
    "for cols in to_drop: \n",
    "    prematch_cols.remove(cols)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "source": [
    "# Sort the dataframe by time\n",
    "df2.sort_values(by='Time', inplace=True)\n",
    "\n",
    "# Modify the function to return only the weighted average columns\n",
    "def calculate_weighted_avg_excluding_current(group, feature_cols, weight_col='Round'):\n",
    "    weighted_avgs = pd.DataFrame(index=group.index)\n",
    "    for col in feature_cols:\n",
    "        cumulative_weighted = (group[col] * group[weight_col]).cumsum().shift(1)\n",
    "        cumulative_weights = group[weight_col].cumsum().shift(1)\n",
    "        weighted_avg = cumulative_weighted / cumulative_weights\n",
    "        weighted_avgs[col + '_WeightedAvg'] = weighted_avg #.fillna(0)\n",
    "    return weighted_avgs\n",
    "\n",
    "# Apply the function to each team group\n",
    "weightedAvg = df2.groupby('Team', group_keys=False).apply(calculate_weighted_avg_excluding_current, feature_cols=feature_cols)\n",
    "\n",
    "# Display the DataFrame with weighted averages\n",
    "weightedAvg.tail()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate current form by avg of last n rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "source": [
    "# Define the window size for rolling averages\n",
    "window_size = 5\n",
    "\n",
    "# Function to calculate rolling averages\n",
    "def calculate_rolling_averages(group):\n",
    "    return group[feature_cols].shift().rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "# Apply the function to df2 grouped by 'Team'\n",
    "rolling_averages = df2.groupby('Team', group_keys=False).apply(calculate_rolling_averages)\n",
    "\n",
    "# Rename columns to indicate rolling averages\n",
    "rolling_averages.columns = [f\"{col}_avg\" for col in rolling_averages.columns]\n",
    "rolling_averages.tail()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "# Combine rolling averages with the original dataframe\n",
    "training_df = pd.concat([df2[prematch_cols].reset_index(drop=True), weightedAvg.reset_index(drop=True), df2[['GF', 'GA', 'Result']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "# training_df.dropna(inplace=True)\n",
    "\n",
    "# # Your training data is now ready\n",
    "training_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "training_df.drop(columns=['Round'], inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "source": [
    "training_df.dropna(inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "source": [
    "training_df.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "# Rename columns to include 'HomeTeam_' prefix where Venue == 1\n",
    "df_team = training_df[training_df['Venue'] == 1].copy()\n",
    "df_team['HomeTeam'] = df_team['Team']\n",
    "df_team.drop(columns=['Team'], inplace=True)\n",
    "df_team['AwayTeam'] = df_team['Opponent']\n",
    "df_team.drop(columns=['Opponent'], inplace=True)\n",
    "df_team = df_team.rename(columns=lambda x: f\"HomeTeam_{x}\" if x not in ['Time', 'Venue', 'HomeTeam', 'AwayTeam'] else x)\n",
    "df_team.drop(columns=['Venue'], inplace=True)\n",
    "df_opponent = training_df[training_df['Venue'] == 0].copy()\n",
    "df_opponent['AwayTeam'] = df_opponent['Team']\n",
    "df_opponent = df_opponent.drop(columns=['Team'])\n",
    "df_opponent['HomeTeam'] = df_opponent['Opponent']\n",
    "df_opponent = df_opponent.drop(columns=['Opponent'])\n",
    "df_opponent = df_opponent.rename(columns=lambda x: f\"AwayTeam_{x}\" if x not in ['Time', 'Venue', 'HomeTeam', 'AwayTeam'] else x)\n",
    "df_opponent.drop(columns=['Venue'], inplace=True)   \n",
    "# Merge the two dataframes\n",
    "df_merged = pd.merge(df_team, df_opponent, on=['Time', 'HomeTeam', 'AwayTeam'])\n",
    "\n",
    "# Calculate head-to-head statistics\n",
    "\n",
    "# Ensure training_df is sorted by 'Time'\n",
    "training_df.sort_values('Time', inplace=True)\n",
    "\n",
    "# Initialize a list to store head-to-head stats\n",
    "h2h_stats = []\n",
    "\n",
    "# Iterate over each match in df_merged\n",
    "for index, row in df_merged.iterrows():\n",
    "    home_team = row['HomeTeam']\n",
    "    away_team = row['AwayTeam']\n",
    "    match_time = row['Time']\n",
    "    \n",
    "    # Filter past matches between the two teams\n",
    "    past_matches = training_df[\n",
    "        (((training_df['Team'] == home_team) & (training_df['Opponent'] == away_team)) |\n",
    "         ((training_df['Team'] == away_team) & (training_df['Opponent'] == home_team))) &\n",
    "        (training_df['Time'] < match_time)\n",
    "    ]\n",
    "    \n",
    "    total_matches = len(past_matches)\n",
    "    if total_matches == 0:\n",
    "        home_wins = away_wins = draws = home_goals = away_goals = 0\n",
    "    else:\n",
    "        # Results from the perspective of the home team\n",
    "        home_wins = ((past_matches['Team'] == home_team) & (past_matches['Result'] == 'W')).sum()\n",
    "        away_wins = ((past_matches['Team'] == home_team) & (past_matches['Result'] == 'L')).sum()\n",
    "        draws = (past_matches['Result'] == 'D').sum()\n",
    "        \n",
    "        # Goals scored by each team\n",
    "        home_goals = past_matches.loc[past_matches['Team'] == home_team, 'GF'].sum() + \\\n",
    "                     past_matches.loc[past_matches['Opponent'] == home_team, 'GA'].sum()\n",
    "        away_goals = past_matches.loc[past_matches['Team'] == away_team, 'GF'].sum() + \\\n",
    "                     past_matches.loc[past_matches['Opponent'] == away_team, 'GA'].sum()\n",
    "    \n",
    "    h2h_stats.append({\n",
    "        'H2H_Total_Matches': total_matches,\n",
    "        'H2H_Home_Wins': home_wins,\n",
    "        'H2H_Away_Wins': away_wins,\n",
    "        'H2H_Draws': draws,\n",
    "        'H2H_Home_Goals': home_goals,\n",
    "        'H2H_Away_Goals': away_goals,\n",
    "    })\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "h2h_stats_df = pd.DataFrame(h2h_stats)\n",
    "\n",
    "# Merge the head-to-head stats with the original dataframe\n",
    "df_merged = pd.concat([df_merged.reset_index(drop=True), h2h_stats_df], axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "df_merged.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "df_merged.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "df_merged.drop(columns=['Time', 'AwayTeam_GF', 'AwayTeam_GA', 'AwayTeam_Result'], inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "source": [
    "df_merged.to_csv('D:\\dev\\project\\Football-Match-Prediction\\data\\processed\\df_merged.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_merged['HomeTeam_Result'] = le.fit_transform(df_merged['HomeTeam_Result'])\n",
    "df_merged['HomeTeam'] = le.fit_transform(df_merged['HomeTeam'])\n",
    "df_merged['AwayTeam'] = le.fit_transform(df_merged['AwayTeam'])\n",
    "\n",
    "y = df_merged['HomeTeam_Result']\n",
    "X = df_merged.drop(columns=['HomeTeam_Result', 'HomeTeam_GF', 'HomeTeam_GA'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "X_train.shape , X_test.shape, y_train.shape, y_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_train:.2f}\")\n",
    "print(f\"Testing Accuracy: {accuracy:.2f}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "# Create a Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate training accuracy\n",
    "y_train_pred = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate testing accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df.reset_index()\n",
    "# Plot the feature importances\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.title('Feature Importance from Random Forest')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-python-3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
