{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c884e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T15:58:03.923364Z",
     "iopub.status.busy": "2024-10-19T15:58:03.922978Z",
     "iopub.status.idle": "2024-10-19T15:58:04.938385Z",
     "shell.execute_reply": "2024-10-19T15:58:04.937172Z"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1729352383414,
     "user": {
      "displayName": "Trần Thuý Hiền",
      "userId": "14633179191388901543"
     },
     "user_tz": -420
    },
    "id": "QjoXTydSZbLm",
    "papermill": {
     "duration": 1.022423,
     "end_time": "2024-10-19T15:58:04.940923",
     "exception": false,
     "start_time": "2024-10-19T15:58:03.918500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from io import StringIO\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c80436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(col, team_name):\n",
    "    if 'Unnamed' in col[0]:\n",
    "        return col[1]\n",
    "    if team_name in col[0]:\n",
    "        return col[1]\n",
    "    return f'{col[0]}__{col[1]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a86d0aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T15:58:04.949543Z",
     "iopub.status.busy": "2024-10-19T15:58:04.948387Z",
     "iopub.status.idle": "2024-10-19T15:58:04.961800Z",
     "shell.execute_reply": "2024-10-19T15:58:04.960905Z"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1729352977568,
     "user": {
      "displayName": "Trần Thuý Hiền",
      "userId": "14633179191388901543"
     },
     "user_tz": -420
    },
    "id": "SAtgQO6eZbLo",
    "papermill": {
     "duration": 0.019833,
     "end_time": "2024-10-19T15:58:04.963973",
     "exception": false,
     "start_time": "2024-10-19T15:58:04.944140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape(start, end, rank_start = 0, rank_end = 20):\n",
    "    if end < 2024:\n",
    "        standings_url = f\"https://fbref.com/en/comps/12/{end}-{end+1}/{end}-{end+1}-La-Liga-Stats\"\n",
    "    else:\n",
    "        standings_url = \"https://fbref.com/en/comps/12/La-Liga-Stats\"\n",
    "    tags = [\"Shooting\", \"Goalkeeping\", \"Passing\", \"Pass Types\",\n",
    "            \"Goal and Shot Creation\", \"Defensive Actions\", \"Possession\", \"Miscellaneous Stats\"]\n",
    "    wait_time = 303\n",
    "    output_dir = \"team_data\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for year in range(end, start - 1, -1):\n",
    "        print(f\"Fetching data for the {year} season...\")\n",
    "        data = requests.get(standings_url)\n",
    "        soup = BeautifulSoup(data.text, 'html.parser')\n",
    "        standings_table = soup.select('table.stats_table')[0]\n",
    "\n",
    "        links = [l.get(\"href\") for l in standings_table.find_all('a')]\n",
    "        links = [l for l in links if '/squads/' in l]\n",
    "        team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
    "\n",
    "        team_urls = team_urls[rank_start:rank_end]\n",
    "\n",
    "        previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n",
    "        standings_url = f\"https://fbref.com{previous_season}\"\n",
    "\n",
    "        for rank, team_url in enumerate(team_urls):\n",
    "            team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "            print(f\"  {rank + 1 + rank_start}. Fetching data for {team_name}...\")\n",
    "            \n",
    "            data = requests.get(team_url)\n",
    "            html_io = StringIO(data.text)\n",
    "            matches = pd.read_html(html_io, match=\"Scores & Fixtures\")[0].drop(columns=[\"Match Report\"])\n",
    "            team_data = matches.copy()\n",
    "\n",
    "            soup = BeautifulSoup(data.text, 'html.parser')\n",
    "            links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "            links = [l for l in links if l and 'matchlogs/all_comps/' in l][1:9] #this pattern is false for Mallorca\n",
    "            for i in range(len(links)):\n",
    "                link = links[i]\n",
    "                print(f\"                 Processing {tags[i]} data...\")\n",
    "                print(link)\n",
    "                success = False\n",
    "                for attempt in range(13):\n",
    "                    try:\n",
    "                        data = requests.get(f\"https://fbref.com{link}\")\n",
    "                        html_io = StringIO(data.text)\n",
    "                        tag = pd.read_html(html_io, match=tags[i])[0]\n",
    "                        success = True\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        print(f\"Attempt {attempt + 1}.  Waiting {wait_time} seconds before retrying...\")\n",
    "                        print(f\"No tables found matching pattern {tags[i]}\")\n",
    "                        time.sleep(wait_time)\n",
    "                if not success:\n",
    "                    raise Exception(f\"Failed to fetch table matching '{tags[i]}' after 13 attempts\")\n",
    "                tag.columns = [combine_columns(col, team_name) for col in tag.columns]\n",
    "                tag = tag.drop(columns=[\"Time\", \"Comp\", \"Round\", \"Day\", \"Venue\", \"Result\", \"GF\", \"GA\", \"Opponent\", \"Match Report\"])\n",
    "\n",
    "                try:\n",
    "                    team_data = team_data.merge(tag, on=\"Date\")\n",
    "                except ValueError:\n",
    "                    print(f\"             Skipping {tags[i]} due to missing data.\")\n",
    "                    continue\n",
    "                time.sleep(random.uniform(20, 30))  \n",
    "\n",
    "            team_data[\"Season\"] = year\n",
    "            team_data[\"Team\"] = team_name\n",
    "            # Save team data to a CSV file after each team is scraped\n",
    "            file_path = os.path.join(output_dir, f\"{team_name}_{year}.csv\")\n",
    "            team_data.to_csv(file_path, index=False)\n",
    "            print(f\"             Data for {team_name} in {year} saved to {file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647388b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T15:58:04.971931Z",
     "iopub.status.busy": "2024-10-19T15:58:04.971540Z",
     "iopub.status.idle": "2024-10-19T16:08:07.935259Z",
     "shell.execute_reply": "2024-10-19T16:08:07.933566Z"
    },
    "id": "YwrnUZgMZbLp",
    "papermill": {
     "duration": 602.970063,
     "end_time": "2024-10-19T16:08:07.937321",
     "exception": true,
     "start_time": "2024-10-19T15:58:04.967258",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for the 2024 season...\n",
      "  6. Fetching data for Mallorca...\n",
      "                 Processing Shooting data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/shooting/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Goalkeeping data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/keeper/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Passing data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/passing/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Pass Types data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/passing_types/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Goal and Shot Creation data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/gca/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Defensive Actions data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/defense/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Possession data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/possession/Mallorca-Match-Logs-All-Competitions\n",
      "                 Processing Miscellaneous Stats data...\n",
      "/en/squads/2aa12281/2024-2025/matchlogs/all_comps/misc/Mallorca-Match-Logs-All-Competitions\n",
      "             Data for Mallorca in 2024 saved to team_data\\Mallorca_2024.csv.\n",
      "  7. Fetching data for Real Betis...\n",
      "                 Processing Shooting data...\n",
      "/en/squads/fc536746/2024-2025/matchlogs/all_comps/schedule/Real-Betis-Scores-and-Fixtures-All-Competitions\n",
      "Attempt 1.  Waiting 303 seconds before retrying...\n",
      "No tables found matching pattern Shooting\n"
     ]
    }
   ],
   "source": [
    "start = 2024\n",
    "end = 2024\n",
    "rank_start = 5\n",
    "rank_end = 20\n",
    "scrape(start, end, rank_start, rank_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d71490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where all team data CSVs are stored\n",
    "data_dir = \"team_data\"\n",
    "all_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "all_data = pd.concat([pd.read_csv(f) for f in all_files], ignore_index=True)\n",
    "\n",
    "# Save the concatenated data to a new CSV\n",
    "all_data.to_csv(\"all_teams_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e314bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6630, 168)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(all_files))\n",
    "x = np.array(all_data)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 642.783544,
   "end_time": "2024-10-19T16:08:09.067593",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-19T15:57:26.284049",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
